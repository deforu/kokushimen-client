# 「自分の代わりにしゃべるマスク」統合サマリ

## 1) 目的・コンセプト

- 着用者の短い発話を**ASR(Whisper)**で文字化 → **LLM**で丁寧な返答に変換 → **TTS**で即発話。
- **言い間違い防止／角の立たない言い回し**を支援し、コミュニケーション負荷を下げる。

---

## 2) システム構成（役割分担）

- **クライアント（マスク側）**：Raspberry Pi Zero 2 W（開発は Pi 5 推奨）。
    - 2本のマイクの**並行ストリーミング**（話者分離の為）、受信音声の**再生**。
- **サーバ（VPS）**：FastAPI + Uvicorn 常駐。
    - 音声受信→**区切り検出**→**ASR**→**LLM**→**TTS**→音声を**WSで返送**。

---

## 3) インフラ前提

- **サービス**：Xserver **VPS**
- **プラン**：VPS 4GB
- **OS**：**Ubuntu 24.04 LTS**（25.04は非LTSで依存が不安定になりやすいため）
- **接続**：WSS(TLS)＋短寿命トークン（Bearer/JWT）／SSH鍵

---

## 4) 主要技術選定

- **ASR**：サーバ内ローカルの **faster-whisper**。
    - 目標：`base`（INT8, beam\_size=1, vad\_filter=True）。ただしVPS 4GB（CPU）でbaseは遅延が出やすい。faster-whisper＋compute_type="int8" / beam_size=1 / vad_filter=True を前提設定にするのもアリ。
- **LLM**：Gemini（短文に最適化したプロンプト）。将来OpenAI/ローカルLLM切替も構想としては可能。
- **TTS**：**VOICEVOX**。**全文合成→一括返却**を基本に、**短文分割＋先出し返送**で体感遅延を低減。
- **入出力**：録音・再生は軽量I/O（`sounddevice`/ALSA 等）。アンプは **PAM8403** or **MAX98357A(I2S)**。

---

## 5) 音声の流れ（実行フロー）

### クライアント（Pi）

1. **WSS接続**（`/ws`）、デバイス・音声仕様・`stream_id`/`role`を送信。
2. **録音送信**：2マイクを**別WSセッション**で並列送信（最小実装）。無音≥400msで`"stop"`通知。
3. **受信再生**：サーバからのASR/LLM/TTS結果を受信し、**ジッタバッファ**経由で再生。
4. **エコー対策**：**TTS再生中は両マイクをミュート**（半二重）。再生直前に**入力バッファをクリア**。

### サーバ（VPS）

1. **音声チャンク受理**（20ms単位推奨）→リングバッファ蓄積。
2. **区切り**（`stop` または無音）で**最終ASR**、途中は**部分ASR**を先出し可能。
3. **LLM**へ投入：**短文先出し**→**最終文**を確定。
4. **TTS**：全文合成→**200msごと**に分割して返送（VOICEVOXは内部非ストリームでもOK）。
5. **監視**：ヘルスチェック、ログ（各工程の遅延）、再試行・再接続制御。

---

## 6) マルチマイク設計（話者切り分け）

- **意図**：相手発話と自分発話を分離して LLM の精度を上げる。
- **方式**：**WS×2**が最短（`stream_id`＝`self`/`other`、`role` メタ付与）。
    - 注意：**USBマイク×2はクロック非同期**。**ビームフォーミング等は行わず**、各ストリームを独立ASR**→テキスト統合**で扱う。

---

## 7) 音声I/Oの仕様（MVPで固定しておくべきポイント）

- **コーデック**：PCM\_S16LE（16-bit little endian）
- **サンプリング**：16,000 Hz / **mono**
- **フレーム長**：**20 ms**（=320 samples → **640 bytes/チャンク**）
- **区切り**：無音≥400 ms でクライアントから `"stop"`
- **整列**：チャンクに `seq` 連番、サーバで `server_ts` を付加し順序を確定
- 将来最適化：**Opus**（20ms, 16–32 kbps）に移行可能

---

## 8) 低遅延・品質の考え方

- 目標体感：**1.2–2.5 秒**（ASR 0.5–1.5s／LLM 0.1–0.4s／TTS 0.3–0.8s＋先出し）
- 縮退順序：**ASR** `base→tiny` → **LLM** 短文テンプレ → **TTS** 軽量（pico/edge-tts 等）
- 再生中のループ防止：**マイクミュート**＋**バッファクリア**＋物理遮音（風防・吸音）

---

## 9) 通信・運用

- **WSS/TLS**、`Authorization: Bearer <短寿命トークン>`。
- **ping/pong**（例 30s）、切断時は**指数バックオフ**で再接続。
- **ジッタバッファ**と**キュー上限**を明示（上限超過時は古いチャンクからドロップ）。

### その他
完成度が上がる“ひとこと仕様”
- タイムスタンプ：サーバ受信ごとに server_ts（ms）を打つ。2本の流れをサーバ時間で整列。
- リトライ：ping/pong 30s／切断時は指数バックオフで再接続。
- ログ：utter_id ごとに rt_asr, rt_llm, rt_tts, rt_total, role, 
- 依存関係によって動作しないことを避けよう
---

## 10) 現時点の合意事項（2025-08-22）

- 言語/実装: クライアント/サーバともに Python で実装。
- エンドポイント: まだ未作成。WSS のパスは今後サーバ実装に合わせて定義。
- 認証: `Authorization: Bearer <token>`（JWT）。発行方法/有効期限は今後定義。
- stream_id: `self` / `other` に固定。2 本のマイクは別 WebSocket セッションで送信。
- デバイス設定: ALSA デバイス名/インデックスはユーザ設定（環境変数 or 設定ファイル）で指定可能。
- 再生時の入出力制御: TTS 再生中は両マイクをミュート（または録音一時停止）。再生直前に入力バッファをクリア。
- 受信音声の分割: サーバからの返送は PCM_S16LE/16kHz/mono を 200ms 単位で分割して送る方針（MVP）。
- モックサーバ: クライアント開発・疎通確認用に簡易モック（FastAPI + WebSocket）を本リポ内に用意。

補足: 上記は MVP の初期合意であり、実装・計測結果に応じて変更する可能性があります。

# 開発の手引書

作りたいもの
概要：。自分の代わりにしゃべってくれるマスク。人とのコミュニケーションにおいて、着用者は簡単な返答をするだけでAIが丁寧な返答に変換してから自動音声で回答をしてくれる。音声はWhisperでテキスト化し、生成AIに相手の発話テキストと自分の発話テキストを送って返答を生成する。最後に返答内容を音声合成してスピーカーから発話する。


動作の流れとしては、以下の通り。
クライアント側（ラズパイ）の処理
1. サーバーのWebSocketエンドポイントに接続します。
2. 録音・送信タスク: `pyaudio`でマイク入力を開始し、継続的に音声データをサーバーに送信します。
3. 受信・再生タスク: サーバーから音声データが送られてくるのを待ち受け、受信したら`pyaudio`でスピーカーから再生します。

サーバー側の処理
1. クライアント(ラズパイ)からWebSocket接続を受け付けます。
2. ラズパイから送られてくる音声ストリームを受信し、一定量（例：無音区間や数秒ごと）で区切ります。
3. **Whisper**で音声データをテキストに変換します。
4. 変換したテキストを**生成AI (ChatGPTなど)**に渡し、応答テキストを生成させます。
    （ローカルLLMで実装するのもアリだが、現状外部のAIを使用）
5. 応答テキストを**VOICEVOXのAPI**に送り、音声データ(WAVファイルなど)を生成します。
6. 生成された音声データをWebSocket経由でラズパイに送り返し 
（Geminiが音声入力も音声出力も兼ねているのなら、この3つの一連の流れがいらなくなるのかも・・・？）

技術構成
- Xseverをサーバー側に使用します。言語はPythonを使います。
- マスク側の組み込みはRaspberry Pi zero2wを使用します（検証の際にはRaspberry Pi 5を使用します）
- 文字起こしはWhisper。サーバー側に構築します。（ローカルで動くって感じ？APIではない）
- AIはGemini
- 音声出力はVoicevoxを使用します。

サーバーの構成
フレームワーク: FastAPI
実行環境: Uvicorn

現在は、上記の構成で考えているのですが異論があれば教えてください。
また、開発にあたっては以下の点に注意してください。

---

# 疑問点
- ストリーミング実装の際に、音声データを受信するサーバーと送信するクライアント側で、チャンク数が異なるとだめですか？
送信側で明示的に 20ms ごとに切って送る方が安定。
- マイクを2つ使うのですが、streamingを2つ接続できるのか
### 方法1: WebSocket接続を2つ確立する
これは最もシンプルで直感的な方法です。マイクごとに専用の通信路を作るイメージです。
- **仕組み**: クライアント（Raspberry Pi）がサーバーに対し、マイクA用とマイクB用に**合計2つのWebSocket接続**を開きます。
- **サーバー側 (FastAPI)**: エンドポイントを分けるか、パスパラメータで識別します。
- **クライアント側 (ラズパイ)**: 2つのマイクからの音声を、それぞれ別々のWebSocketクライアントで並行してサーバーに送信します。
**メリット** 👍
- **実装が非常にシンプル**: シングルストリームのコードをほぼそのまま2つ分用意すればよく、理解しやすいです。
- **疎結合**: 片方のストリーム（マイク）に問題が発生しても、もう片方に影響を与えません。
- **処理の分離が容易**: サーバー側でマイクごとの処理を完全に分けて記述できます。
**デメリット** 👎
- **リソース消費**: 接続数が2倍になるため、サーバーのリソース（メモリやファイルディスクリプタ）をわずかに多く消費します。
- **接続管理**: 2つの接続の確立、切断、再接続をそれぞれ管理する必要があります。

決定する事
- 音声データの形式: ラズパイとサーバー間でやり取りする音声データは、どのような形式（サンプリングレート, ビット深度, チャンネル数）にするか、あらかじめ決めておきましょう。pyaudioで扱う形式と、Whisperが受け取れる形式を揃えておく必要があります。

### メモ
- 生成AIについて、短文生成なので軽量なのを選びたい

完成度が上がる“ひとこと仕様”
- タイムスタンプ：サーバ受信ごとに server_ts（ms）を打つ。2本の流れをサーバ時間で整列。
- リトライ：ping/pong 30s／切断時は指数バックオフで再接続。
- ログ：utter_id ごとに rt_asr, rt_llm, rt_tts, rt_total, role, stream_id。
